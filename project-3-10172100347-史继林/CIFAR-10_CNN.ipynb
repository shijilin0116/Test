{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r'C:\\Users\\CZY\\Desktop\\AI_project3\\cifar-10-batches-py/batches.meta', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Activation,Flatten,BatchNormalization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def unpickle(file):\n",
    "      with open(file, 'rb') as fo:\n",
    "              dict = pickle.load(fo, encoding='bytes')\n",
    "      return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集文件\n",
    "test_batch = unpickle(R'C:\\Users\\CZY\\Desktop\\AI-3\\cifar-10-batches-py/test_batch')\n",
    "\n",
    "X_test = np.array(test_batch[b'data'])\n",
    "y_test = np.array(test_batch[b'labels']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集文件\n",
    "train_files = ['data_batch_'+str(i) for i in range(1,6)]\n",
    "\n",
    "train_data_list,train_label_list = [],[]\n",
    "\n",
    "for f in train_files:\n",
    "    \n",
    "    fpath = r'C:\\Users\\CZY\\Desktop\\AI-3\\cifar-10-batches-py/' + f\n",
    "    batch_dict = unpickle(fpath)\n",
    "    \n",
    "    batch_data = batch_dict[b'data']\n",
    "    batch_labels = batch_dict[b'labels']\n",
    "    train_data_list.append(batch_data)\n",
    "    train_label_list.append(batch_labels)\n",
    "\n",
    "X_train = np.concatenate(train_data_list, axis = 0)\n",
    "y_train = np.concatenate(train_label_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names_batch = unpickle(r'C:\\Users\\CZY\\Desktop\\AI-3\\cifar-10-batches-py/batches.meta')\n",
    "label_names = label_names_batch[b'label_names']\n",
    "label_names = [l.decode(\"utf-8\") for l in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征： (50000, 3072) ，训练集label (50000,)\n",
      "测试集特征： (10000, 3072) ，测试集label (10000,)\n",
      "类别名字： ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print('训练集特征：',X_train.shape,'，训练集label',y_train.shape)\n",
    "print('测试集特征：',X_test.shape,'，测试集label', y_test.shape)\n",
    "print(\"类别名字：\",label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,3,32,32)\n",
    "X_test = X_test.reshape(-1,3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# 归一化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 将class vectors转变成binary class metrics\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: th\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Switch backend\n",
    "keras.backend.set_image_dim_ordering('th')\n",
    "print('Backend:',keras.backend.image_dim_ordering())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(opt):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu')\n",
    "    MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())   \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512))  \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 32, 32)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               33554944  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 33,579,466\n",
      "Trainable params: 33,579,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt1 = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "cnn2 = base_model(opt1)\n",
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "batch_size = 100\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CZY\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 567s 11ms/step - loss: 1.6415 - acc: 0.4121 - val_loss: 1.3445 - val_acc: 0.5297\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 539s 11ms/step - loss: 1.3009 - acc: 0.5399 - val_loss: 1.2011 - val_acc: 0.5825\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 537s 11ms/step - loss: 1.1619 - acc: 0.5935 - val_loss: 1.1212 - val_acc: 0.6111\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 538s 11ms/step - loss: 1.0627 - acc: 0.6307 - val_loss: 1.0775 - val_acc: 0.6286\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 538s 11ms/step - loss: 0.9881 - acc: 0.6567 - val_loss: 1.0305 - val_acc: 0.6396\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 537s 11ms/step - loss: 0.9255 - acc: 0.6820 - val_loss: 1.0176 - val_acc: 0.6525\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 538s 11ms/step - loss: 0.8738 - acc: 0.6996 - val_loss: 0.9612 - val_acc: 0.6661\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 538s 11ms/step - loss: 0.8373 - acc: 0.7135 - val_loss: 0.9833 - val_acc: 0.6690\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 537s 11ms/step - loss: 0.8075 - acc: 0.7244 - val_loss: 0.9782 - val_acc: 0.6711\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 538s 11ms/step - loss: 0.7806 - acc: 0.7339 - val_loss: 1.1934 - val_acc: 0.6454\n"
     ]
    }
   ],
   "source": [
    "history = cnn2.fit(X_train, y_train, \n",
    "                    epochs = 10, batch_size = 32, \n",
    "                    validation_data=(X_test,y_test), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
